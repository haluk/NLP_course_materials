{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation with Attention\n",
    "\n",
    "In this notebook we will show you how to train a `seq2seq` model for English to\n",
    "Turkish translation. When you train the model, you will be able to translate\n",
    "English sentences to Turkish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import Video\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections of the Notebook\n",
    "1. [Loading the Dataset](#load)\n",
    "2. [Tokenizing and Encoding](#tokenize_encode)\n",
    "3. [Embeddings](#embeddings)\n",
    "4. [The Model and Training](#model)<br>\n",
    "    4.1 [Custom Loss and Accuracy](#loss_acc)\n",
    "5. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### 1. Loading the Dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. They\n",
    "provide translation datasets for 80 different languages to/from English. The\n",
    "dataset is in tab separated tabular format with 3 columns. First column is a\n",
    "sentence in one of the 80 languages, and second is its translation in English.\n",
    "Third column shows the source of the row. We can ignore third column for our\n",
    "purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input language  => Training size: 106280\tValidation size: 26571\n",
      "Target language => Training size: 106280\tValidation size: 26571\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    \"tur-eng.zip\", origin=\"https://github.com/haluk/NLP_course_materials/blob/master/hw4/tur-eng.zip?raw=true\",\n",
    "    extract=True)\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/tur.txt\"\n",
    "\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = utils.load_dataset(\n",
    "    path_to_file, None\n",
    ")\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "(\n",
    "    input_tensor_train,\n",
    "    input_tensor_val,\n",
    "    target_tensor_train,\n",
    "    target_tensor_val,\n",
    ") = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(\n",
    "    \"{:15s} => {:10s}: {}\\t{:15s}: {}\".format(\n",
    "        \"Input language\",\n",
    "        \"Training size\",\n",
    "        len(input_tensor_train),\n",
    "        \"Validation size\",\n",
    "        len(input_tensor_val),\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"{:15s} => {:10s}: {}\\t{:15s}: {}\".format(\n",
    "        \"Target language\",\n",
    "        \"Training size\",\n",
    "        len(target_tensor_train),\n",
    "        \"Validation size\",\n",
    "        len(target_tensor_val),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `tf.data.Dataset` API for building an asynchronous, highly optimized\n",
    "data pipeline to prevent GPUs from data starvation. It loads data from the disk,\n",
    "text in our case, creates batches and sends it to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor_train, target_tensor_train)\n",
    ").shuffle(BUFFER_SIZE)\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Models\n",
    "\n",
    "We will use [Jay Alammar's](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) wonderful visualizations to explain `seq2seq` model and `attention` mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://jalammar.github.io/images/seq2seq_2.mp4\" controls  width=\"900\"  height=\"200\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://jalammar.github.io/images/seq2seq_2.mp4\", width=900, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Machine Translation (NMT) model is composed of an `encoder` and `decoder`. Encoder part of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://jalammar.github.io/images/seq2seq_4.mp4\" controls  width=\"900\"  height=\"200\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"https://jalammar.github.io/images/seq2seq_4.mp4\", width=900, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "Please contact Haluk Dogan (<a href=\"mailto:hdogan@vivaldi.net\">hdogan@vivaldi.net</a>) for further questions or inquries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
