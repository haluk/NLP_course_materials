{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering with BiLSTM and Attention\n",
    "\n",
    "In this notebook, we will build a question answering (QA) deep learning architecture. To fully utilize the available context information, we will make use of BiLSTM units. Instead of one-hot encoding words, we will use GloVe embeddings to make lexical semantics available to the model. We follow the architecture shown in the figure below copied from our [textbook](https://web.stanford.edu/~jurafsky/slp3/25.pdf) (Fig 25.7). We differ in the representation of the context: we only use GloVe embeddings while the architecture in the textbook uses an enriched representation with POS, NER tags, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QA-Deep-Learning-Architecture](img/arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import arch_utils\n",
    "import utils\n",
    "from layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections of the Notebook\n",
    "1. [Loading the Dataset](#load)\n",
    "2. [Tokenizing and Encoding](#tokenize_encode)\n",
    "3. [Embeddings](#embeddings)\n",
    "4. [The Model and Training](#model)<br>\n",
    "    4.1 [Custom Loss and Accuracy](#loss_acc)\n",
    "5. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "### 1. Loading the Dataset\n",
    "\n",
    "We will use the [SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). This dataset is available in TensorFlow and we will use the TensorFlow dataset ([tfds](https://www.tensorflow.org/datasets/api_docs/python/tfds) loader). We will extract the context, question text, answer text and the starting position of the answer. We will do processing later in the notebook to shape the input into a form that our architecture can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = Path.cwd().as_posix()\n",
    "\n",
    "# Load data\n",
    "squad_data, info = tfds.load(\"squad\", data_dir=CWD, with_info=True)\n",
    "\n",
    "# Get training and validation splits\n",
    "squad_train = squad_data[\"train\"]\n",
    "squad_validation = squad_data[\"validation\"]\n",
    "print(info.features)\n",
    "\n",
    "# Get context, question and answer text and starting point of answer in the context \n",
    "# (in number of words from the beginning of the context)\n",
    "context_tr, question_tr, answer_text_tr, answer_start_tr = utils.split_info(squad_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We can look at an example from the training set, e.g. 5th example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "start_char_idx = answer_start_tr[i]\n",
    "print(\"Context: \".upper(), context_tr[i], \"\\n\")\n",
    "print(\"Context until answer: \".upper(), context_tr[i][0:start_char_idx-1], \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Question: \".upper(), question_tr[i], \"\\n\")\n",
    "print(\"Answer: \".upper(), answer_text_tr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tokenize_encode'></a>\n",
    "### 2. Tokenizing and Encoding\n",
    "\n",
    "We use [TensorFlow Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) and map to integers as in the previous homeworks.\n",
    "\n",
    "We post-pad the resulting context and answer vectors to equal lengths for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_type = \"post\"\n",
    "\n",
    "# mark out of vocabulary words\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizer = Tokenizer(oov_token=oov_token)\n",
    "\n",
    "# tokenize texts\n",
    "tokenizer.fit_on_texts(context_tr)\n",
    "\n",
    "# mapping between words and integers in the vocabulary\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# size of the vocabulary\n",
    "num_words = len(word_index.keys())\n",
    "\n",
    "print(\"{:50s}: {}\".format(\"Total number of words\", num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding context vectors to integer vectors and post padding them \n",
    "sequences = tokenizer.texts_to_sequences(context_tr)\n",
    "context_len = max(map(len, sequences))\n",
    "print(\"{:50s}: {}\".format(\"Max length of a context vector\", context_len))\n",
    "context_padded = pad_sequences(sequences, maxlen=context_len, padding=padding_type)\n",
    "\n",
    "# encoding question vectors to integer vectors and post padding them \n",
    "sequences = tokenizer.texts_to_sequences(question_tr)\n",
    "question_len = max(map(len, sequences))\n",
    "print(\"{:50s}: {}\".format(\"Max length of a question vector\", question_len))\n",
    "question_padded = pad_sequences(sequences, maxlen=question_len, padding=padding_type)\n",
    "\n",
    "# encoding answer vectors into integer vectors\n",
    "answer_token = tokenizer.texts_to_sequences(answer_text_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want the examples whose contexts contain the exact answer. The example shown above will be excluded. Some of the words in the context are removed during tokenizing. We will need to search for the answer in the proximity of the given answer start position. We set the search window length to 10 before and after the given start position.\n",
    "\n",
    "Here, we also form our labels for the dataset in the form of (answer_start, answer_end). We will use the length of the given answer text for that. The labels will be in one-hot encoding format where a 1 indicates either the start or the end of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tup = []  # (start,end)\n",
    "selected = []  # we keep context that only contains exact answer\n",
    "WINDOW = 10\n",
    "\n",
    "for i in range(len(answer_start_tr)):\n",
    "    start_char_idx = answer_start_tr[i]\n",
    "    start = len(context_tr[i][0 : start_char_idx - 1].replace(\"-\", \" \").split()) + 1\n",
    "    answer_len = len(answer_text_tr[i].replace(\"-\", \" \").split())\n",
    "    end = start + answer_len\n",
    "\n",
    "    for j in range(start - WINDOW, start + WINDOW):\n",
    "        if np.array_equal(context_padded[i][j : j + answer_len], answer_token[i]):\n",
    "            start = j\n",
    "            end = j + answer_len - 1\n",
    "            y_train_tup.append((start, end))\n",
    "            selected.append(i)\n",
    "            break\n",
    "\n",
    "context_padded_clean = context_padded[selected]\n",
    "question_padded_clean = question_padded[selected]\n",
    "answer_text_clean = answer_text_tr[selected]\n",
    "\n",
    "num_train_data = context_padded_clean.shape[0]\n",
    "print(\"{:50s}: {}\".format(\"Number of training samples after cleaning\", num_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(len(context_padded_clean)):\n",
    "    s = np.zeros(context_len, dtype=\"float32\")\n",
    "    e = np.zeros(context_len, dtype=\"float32\")\n",
    "\n",
    "    s[y_train_tup[i][0]] = 1\n",
    "    e[y_train_tup[i][1]] = 1\n",
    "\n",
    "    y_train.append(np.concatenate((s, e)))\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embeddings'></a>\n",
    "### 3. Embeddings\n",
    "\n",
    "We will use the 50 dimensional GloVe embeddings. Below are embedding vectors for some tokens e.g \"the\", \"a\", \".\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head glove.6B.50d.txt | cat -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 50 # glove.6B.50d\n",
    "embeddings_mat = arch_utils.load_embeddings(\"glove.6B.50d.txt\", num_words, emb_dim, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "### 4. The Model and Training\n",
    "\n",
    "Our model will have two inputs: context and question vectors. We define an input layer for each. We will feed each type of input to Embedding layer and BiLSTM layer. Each group of Embedding+BiLSTM group will be parametrized separately. We will implement the attention mechanism in the BiLinear layer where we find the similarity between the context and the question.\n",
    "\n",
    "We will use the functional Keras API this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 128\n",
    "context_input = Input(shape=(context_len,))\n",
    "context_emb = Embedding(num_words, embeddings_mat, emb_dim)(context_input)\n",
    "context_lstm = BiLSTM(units)(context_emb)\n",
    "\n",
    "question_input = Input(shape=(question_len,))\n",
    "question_emb = Embedding(num_words, embeddings_mat, emb_dim)(question_input)\n",
    "question_lstm = BiLSTM(units)(question_emb)\n",
    "\n",
    "y_prob = BiLinear_Layer(2 * units, question_len)(context_lstm, question_lstm)\n",
    "\n",
    "model = Model(inputs=[context_input, question_input], outputs=y_prob)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loss_acc'></a>\n",
    "### 4.1 Custom Loss and Accuracy\n",
    "We will use a custom loss and accuracy to evaluate our model. This is because we are predicting both the start and the end of the answer in the context. Specifically, for each position in the context, our model predicts the probability that it's the start of the answer and the probability that it's the end of the answer. To reflect this and summarize into a single metric, we sum the binary crossentropies to find the custom loss. While calculating the accuracy, we report the proportion of exact matches for the start and end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=arch_utils.loss,\n",
    "    metrics=[arch_utils.Custom_Accuracy(num_train_data)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training takes a long time, here we show only the first two epochs. In the batch submission, we will expect you to train for longer. Details are in the [Exercises](#exercises) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_padded_jupyter = context_padded_clean[:1000]\n",
    "question_padded_jupyter = question_padded_clean[:1000]\n",
    "y_train_jupyter = y_train[:1000]\n",
    "\n",
    "# model.load_weights(\"epochs_1000\")\n",
    "init_epoch = 0\n",
    "num_epochs = 2\n",
    "batch_size = 128\n",
    "\n",
    "# early stopping will depend on the validation loss\n",
    "# patience parameter determines how many epochs with no improvement\n",
    "# in validation loss will be tolerated\n",
    "# before training is terminated.\n",
    "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "\n",
    "filepath = \"epochs_{epoch:03d}\"\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=True)\n",
    "\n",
    "callbacks = [earlystopping, checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    x=[context_padded_jupyter, question_padded_jupyter],\n",
    "    y=y_train_jupyter,\n",
    "    # keep 10% of the training data for validation\n",
    "    validation_split=0.1,\n",
    "    initial_epoch=init_epoch,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,  # Logs once per epoch.\n",
    "    batch_size=batch_size,\n",
    "    # Our neural network will be trained\n",
    "    # with stochastic (mini-batch) gradient descent.\n",
    "    # It is important that we shuffle our input.\n",
    "    shuffle=True,  # set to True by default\n",
    ")\n",
    "\n",
    "# Print training history\n",
    "history = history.history\n",
    "print(\n",
    "    \"\\nValidation accuracy: {acc}, loss: {loss}\".format(\n",
    "        acc=history[\"val_custom_accuracy\"][-1], loss=history[\"val_loss\"][-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercises'></a>\n",
    "### 5. Exercises\n",
    "\n",
    "###### 1. In the homework bundle, we provide the weights trained up to epoch 1500. Submit a batch job to train it for another 1000 epochs.\n",
    "###### 2. With the model trained for 2500 epochs, report the accuracy. ~%20 of training data is set aside for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "Please contact Haluk Dogan (<a href=\"mailto:hdogan@vivaldi.net\">hdogan@vivaldi.net</a>) for further questions or inquries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
